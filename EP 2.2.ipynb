{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [MAC0417] Visão e Processamento de Imagens - Exercício Programa 2.1\n",
    "*16 de Novembro de 2020*\n",
    "\n",
    "## Introdução \n",
    "Na primeira parte deste exercício programa, produzimos uma base de imagens aumentada a partir das banco de dados do **EP1**, aplicando alguns filtros. Então geramos visualizações dos dados.\n",
    "\n",
    "Integrantes do grupo:\n",
    "\n",
    "| Nome | NUSP |\n",
    "|------|------|\n",
    "| Daniela Favero | 10277443 |\n",
    "| Mateus Barbosa | 8993368 |\n",
    "| Vitor Guidi | 8038091 |\n",
    "\n",
    "A base de dados e os metadados se encontram no nosso repositório do [GitHub](https://github.com/danigfavero/Visao-computacional-e-processamento-de-imagens).\n",
    "\n",
    "O código a seguir gera (caso não existam) os diretórios que abrigarão as imagens normalizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filters = [\n",
    "    \"normalized_grayscale/\",\n",
    "    \"normalized_exp/\",\n",
    "    \"normalized_log/\",\n",
    "    \"normalized_mean/\", \n",
    "    \"normalized_gradient/\"\n",
    "]\n",
    "objs = [\"colheres\",\n",
    "            \"garfos\",\n",
    "            \"canecas\",\n",
    "            \"facas\",\n",
    "            \"panelas\",\n",
    "            \"frigideiras\",\n",
    "            \"controles_remotos\",\n",
    "            \"calcas\",\n",
    "            \"casacos\",\n",
    "            \"camisetas\"]\n",
    "\n",
    "for filt in filters:\n",
    "    try:\n",
    "        os.mkdir(filt)\n",
    "    except FileExistsError:\n",
    "        continue\n",
    "\n",
    "for filt in filters:\n",
    "    for obj in objs:\n",
    "        try:\n",
    "            os.mkdir(filt + obj)\n",
    "        except FileExistsError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `data_augmentation` abaixo é a mesma do EP2.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "def data_augmentation(input_directory, output_directory, func):\n",
    "    objs = [\"colheres/COLHER\",\n",
    "            \"garfos/GARFO\",\n",
    "            \"canecas/CANECA\",\n",
    "            \"facas/FACA\",\n",
    "            \"panelas/PANELA\",\n",
    "            \"frigideiras/FRIGIDEIRA\",\n",
    "            \"controles_remotos/CONTROLE\",\n",
    "            \"calcas/CALCA\",\n",
    "            \"casacos/CASACO\",\n",
    "            \"camisetas/CAMISETA\"]\n",
    "    times = [\"NOITE\", \"DIA\"]\n",
    "    illums = [ \"INDOOR\", \"OUTDOOR\" ]\n",
    "    backgrounds = [ \"CLARO\", \"MADEIRA\", \"ESCURO\" ]\n",
    "    repeats = [\"a\", \"b\", \"c\"]\n",
    "    nums = ['1', '2', '3']\n",
    "\n",
    "    path = output_directory\n",
    "    \n",
    "    suffixes = list(map(\"\".join, itertools.product(*[backgrounds, nums, repeats, [\".jpg\"]])))\n",
    "    \n",
    "    for it in itertools.product(*[objs, times, illums, suffixes]):\n",
    "        suffix = \"_\".join(it)\n",
    "        url = input_directory + suffix\n",
    "        path = output_directory + suffix\n",
    "        for _ in range(3): # evitando erros de conexão (3 tentativas)\n",
    "            try:\n",
    "                img = io.imread(url).astype(np.uint8)\n",
    "                img = func(img)\n",
    "                io.imsave(path, img)\n",
    "            except ConnectionResetError:\n",
    "                continue\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização das imagens\n",
    "\n",
    "Realizamos uma normalização de histograma em todas as imagens do `augmentedDataset`,\n",
    "usando a função `data_augmentation` definida acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import equalize_hist\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "# normalizing all datasets\n",
    "data_augmentation(\"grayscale/\",\"normalized_grayscale/\", equalize_hist)\n",
    "data_augmentation(\"log/\",\"normalized_log/\", equalize_hist)\n",
    "data_augmentation(\"exp/\",\"normalized_exp/\", equalize_hist)\n",
    "data_augmentation(\"gradient/\",\"normalized_gradient/\", equalize_hist)\n",
    "data_augmentation(\"mean/\",\"normalized_mean/\", equalize_hist)\n",
    "\n",
    "\n",
    "# img_top = io.imread(\"~/Desktop/nova/Visao-computacional-e-processamento-de-imagens/grayscale/colheres/COLHER_DIA_INDOOR_CLARO1a.jpg\").astype(np.uint8)\n",
    "# imshow(equalize_hist(img_top), cmap='gray')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geração de estatísticas relativas às imagens\n",
    "O código a seguir gera 3 estatísticas relativas a cada classe e cada filtro em nossas *databases*: o protótipo médio (média dos níveis de cinza de cada imagem) e a média e variância dos histogramas dessas imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import functools \n",
    "\n",
    "def avg_prototype(input_directory):\n",
    "    images, tamanho = list(get_all_images_from_folder(input_directory))\n",
    "    return functools.reduce(np.add, images, np.zeros((2000,1500)) ) / tamanho\n",
    "    \n",
    "def generate_histograms(input_directory):\n",
    "    images, tamanho = list(get_all_images_from_folder(input_directory))\n",
    "    return np.array( [ hist for (hist,edges) in list( map(lambda x : np.histogram(x,bins=256), images) ) ] )\n",
    "\n",
    "def histogram_metrics(histograms):\n",
    "    return histograms.var(0), np.mean(histograms, axis=0)\n",
    "    \n",
    "from os import walk\n",
    "from skimage.transform import resize\n",
    "def get_all_images_from_folder(path):\n",
    "    #tomar cuidado para usar o nome do arquivo dentro da pasta\n",
    "    #walk nao retorna o path completo\n",
    "    #path, ie = 'grayscale/colheres/'\n",
    "    #chamar com / apos fim da pasta\n",
    "\n",
    "    f = []\n",
    "    for (dirpath, dirnames, filenames) in walk(path):\n",
    "        for file in filenames:\n",
    "            f.append(dirpath + file)\n",
    "       \n",
    "    return map(lambda x : resize(io.imread(x).astype(np.uint8), (2000,1500), anti_aliasing=True), f), len(f)\n",
    "\n",
    "# for img in get_all_images_from_folder(\"grayscale/colheres/\"):\n",
    "#     imshow(img, cmap='gray')\n",
    "# prototipo = avg_prototype(\"grayscale/colheres/\")\n",
    "#lista = generate_histograms(\"grayscale/colheres/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `plot_stats_class` a seguir gera um gráfico contendo as 3 estatísticas geradas pelas funções acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stats_class(class_directory):\n",
    "    lista = generate_histograms(class_directory)\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "    fig.suptitle('Avg/Var plot for histogram')\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    ax1.imshow(avg_prototype(class_directory), cmap='gray')\n",
    "    ax2.plot([x for x in range(256)], lista[1])\n",
    "    ax3.plot([x for x in range(256)], lista[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, chamamos `plot_stats_class` a fim de visualizar as estatísticas, usando uma classe como representante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stats():\n",
    "    filters = ['exp', 'gradient', 'grayscale', 'log', 'mean']\n",
    "    norm_filters = ['normalized_exp',\n",
    "                    'normalized_gradient',\n",
    "                    'normalized_grayscale',\n",
    "                    'normalized_log',\n",
    "                    'normalized_mean']\n",
    "    all_filters = [filters, norm_filters]\n",
    "    for category in all_filters:\n",
    "        for f in category:\n",
    "            plot_stats_class(f + \"/colheres/\") # PORQUE GOSTAMOS DE COLHERES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
